{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c6f9d39-aabf-4519-9121-363590a5c319",
   "metadata": {},
   "source": [
    "# Random Forest Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c955865b-ecac-4964-a577-f9e81596d130",
   "metadata": {},
   "source": [
    "### Random Forest advantages :\n",
    "1. Reduced Overfitting\n",
    "2. Robustness\n",
    "3. Feature Importance\n",
    "4. Non-linearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e65ee93d-806f-4937-a636-f28b82ce2574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Library\n",
    "\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a33b41b8-64c4-4eb1-85d9-a9ef190b1c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Leaf:\n",
    "    def __init__(self, value):\n",
    "        self.value = value\n",
    "\n",
    "    def predict(self, row):\n",
    "        return self.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75296a60-9a91-43fd-906f-fb8b566a9b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, level, split_feature, split_value, left_node=None, right_node=None):\n",
    "        self.level            = level\n",
    "        self.split_feature    = split_feature\n",
    "        self.split_value      = split_value\n",
    "        self.left_node        = left_node\n",
    "        self.right_node       = right_node\n",
    "\n",
    "    def predict(self, row):\n",
    "        if row[self.split_feature] >= self.split_value:\n",
    "            return self.right_node.predict(row)\n",
    "        return self.left_node.predict(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a84eb9cb-4027-4e6b-9c4d-c83c129bee53",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GiniDecisionTreeClassifier:\n",
    "\n",
    "    def __init__(self, max_depth):\n",
    "        self.max_depth = max_depth\n",
    "        self.root      = None\n",
    "\n",
    "    def set_root(self, node):\n",
    "        if self.root == None:\n",
    "            self.root = node\n",
    "\n",
    "    def class_counts(self, y):\n",
    "        '''\n",
    "        return for each unique member in y (label) his number of appearances\n",
    "        '''\n",
    "        values, counts = np.uniquely(y, return_counts=True)\n",
    "        return values, counts\n",
    "\n",
    "    def calc_popular_class(self, y):\n",
    "        '''\n",
    "        return the most popular class in y\n",
    "        '''\n",
    "        values, counts = self.class_counts(y)\n",
    "        idx            = np.argmax(counts)\n",
    "        popular_class  = values(idx)\n",
    "        return popular_class\n",
    "\n",
    "    def calc_gini(self, y):\n",
    "        '''\n",
    "        Gini score is used to evaluate the impurity of a set of samples within a particular node of the tree.\n",
    "        Gini = 1 - sum(p^2)\n",
    "        '''\n",
    "        values, counts      = self.class_counts(y)\n",
    "        class_probabilities = counts / float(len(y))\n",
    "        return 1 - np.sum(class_probabilities**2, axis=0)\n",
    "\n",
    "    def features_to_check(self, num_features):\n",
    "        '''\n",
    "        Instead of checking all the possible features, we check only some of them that we choose randomly,\n",
    "        it's acceptableto choose the square root of the number of features.\n",
    "        '''\n",
    "        if num_features <= 0:\n",
    "            raise ValueError(\"Number of features must be positive.\")\n",
    "        \n",
    "        num_features_to_check = int(math.sqrt(num_features))\n",
    "        idxs                  = np.random.randint(0, num_features, size=num_features_to_check)\n",
    "        return idxs\n",
    "\n",
    "    def get_best_split(self, X, y):\n",
    "        '''\n",
    "        return the best split for the given X and y\n",
    "        '''\n",
    "        num_features            = X.shape[1]\n",
    "        num_rows                = len(y)\n",
    "        best_split_feature      = 0\n",
    "        best_split_value        = 0\n",
    "        best_gini               = 1\n",
    "\n",
    "        for feature in self.features_to_check(num_features-1):\n",
    "            values = np.unique(X[:, feature])\n",
    "            for va in values:\n",
    "\n",
    "                # split data for specific value and feature:\n",
    "                right_rows, right_labels, left_rows, left_labels = self.data_split(X, y, feature, val)\n",
    "\n",
    "                # calc average gini - (check if split good):\n",
    "                p = float(len(right_rows)) / num_rows\n",
    "                average_gini = p * self.calc_gini(right_labels)/num_rows + (1-p) * \\\n",
    "                               self.calc_gini(left_labels)/num_rows\n",
    "\n",
    "                if average_gini < best_gini:\n",
    "                    best_gini = average_gini\n",
    "                    best_split_feature, best_split_value = feature, val\n",
    "\n",
    "        return best_split_feature, best_split_value, best_gini\n",
    "\n",
    "\n",
    "    def data_split(self, X, y, split_feature, split_value):\n",
    "        '''\n",
    "        split data by feature and value\n",
    "        '''\n",
    "        # right:\n",
    "        idx_right_subtree    = X[:, split_feature] >= split_value\n",
    "        right_subtree        = X[idx_right_subtree]\n",
    "        right_subtree_labels = y[idx_right_subtree]\n",
    "\n",
    "        # left:\n",
    "        idx_left_subtree    = X[:, split_feature] >= split_value\n",
    "        lft_subtree        = X[idx_left_subtree]\n",
    "        left_subtree_labels = y[idx_left_subtree]\n",
    "\n",
    "        return right_subtree, right_subtree_labels, left_subtree, left_subtree_labbels\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        '''\n",
    "        building the tree\n",
    "        '''\n",
    "        self.set_root(self.split_node(X, y))\n",
    "\n",
    "    def split_node(self, X, y, node_level=0):\n",
    "        '''\n",
    "        recursive function that set the nodes of the tree.\n",
    "        '''\n",
    "        node_level += 1\n",
    "\n",
    "        # stop condition #1\n",
    "        if len(y) == 1:\n",
    "            return leaf(y[0])\n",
    "\n",
    "        split_feature, split_value, gini  = self.get_best_split(X, y)\n",
    "\n",
    "        # stop condition #2\n",
    "        if gini == 0.0 or self.max_depth < node_level :\n",
    "            popular_class = self.calc_popular_class(y)\n",
    "            return Leaf(popular_class)\n",
    "\n",
    "        right_subtree, right_subtree_labels, left_subtree, left_subtree_labels = self.data_split(X, y, split_feature, split_value)\n",
    "\n",
    "        # stop condition #3\n",
    "        if len(right_subtree_labels) == 1:\n",
    "            return Leaf(right_subtree_labels[0])\n",
    "        if len(left_subtree_labels) == 1:\n",
    "            return Leaf(left_subtree_labels[0])\n",
    "\n",
    "        right_node = self.split_node(right_subtree, right_subtree_labels, node_level)\n",
    "        left_node  = self.split_node(left_subtree, left_subtree_labels, node_level)\n",
    "\n",
    "        return Node(node_level, split_feature, split_value, left_node, right_node)\n",
    "\n",
    "    def predict_labels(self, X_test):\n",
    "        y_probs = []\n",
    "\n",
    "        for row in X_test:\n",
    "            y_probs.append(self.root.predict(row))\n",
    "\n",
    "        return np.asarray(y_probs)\n",
    "\n",
    "    def get_accuracy(self, y, y_probs):\n",
    "        correct = y == y_probs\n",
    "        acc = ( np.sum(correct) / float(len(y))) * 100.0\n",
    "        return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "740c21f6-1a35-411f-a807-072643feede6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForest:\n",
    "    def __init__(self):\n",
    "        self.forest = []\n",
    "\n",
    "    def create_subsample(self, X, y, a=0.25):\n",
    "        '''\n",
    "        return sub sample of size n' of the dataset.\n",
    "        n' = a*n\n",
    "        '''\n",
    "        n             = len(y)\n",
    "        n_tag         = int(a*n)\n",
    "        idx           = np.random.randint(0, n, size=n_tag)\n",
    "        X_subsample   = X[idx]\n",
    "        y_subsample   = y[idx]\n",
    "        return X_subsample, y_subsample\n",
    "\n",
    "    def fit(self, X, y, T=300, max_depth=4):\n",
    "        '''\n",
    "        build the forest.\n",
    "        T : number of trees in the forest. The default is 300.\n",
    "        '''\n",
    "        for i in range(0, T):\n",
    "            X_subsample, y_subsample = self.create_subsample(X, y)\n",
    "            tree = GiniDecisionTreeClassifier(max_depth)\n",
    "            tree.fit(X_subsample, y_subsample)\n",
    "            self.forest.append(tree)\n",
    "            \n",
    "    def calc_popular_class(self, y):\n",
    "        values, counts = np. unique(y, return_counts=True)\n",
    "        idx            = np.argmax(counts)\n",
    "        popular_class  = values[idx]\n",
    "        return popular_class\n",
    "\n",
    "    def bagging_predict(self, X_test):\n",
    "        predictions = []\n",
    "\n",
    "        for row in X_test:\n",
    "            all_trees_preds = np.asarray([tree.root.predict(row) for tree in self.forest])\n",
    "            predictions.append(self.calc_popular_class(all_trees_preds))\n",
    "\n",
    "        return np.asarray(predictions)\n",
    "\n",
    "    def get_accuracy(self, y, y_probs):\n",
    "        correct = y == y_probs\n",
    "        acc     = ( np.sum(correct) / float(len(y)) ) * 100.0\n",
    "        return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98cdfa43-2fe4-4e2b-9eba-dd22692706df",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99d8584-ebdb-4666-9fd9-bb544e589c4a",
   "metadata": {},
   "source": [
    "## Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "517500c5-41bd-4d42-adc8-b4e750bb2d38",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Number of features must be positive.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m model_selection\u001b[38;5;241m.\u001b[39mtrain_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.25\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m      8\u001b[0m forest \u001b[38;5;241m=\u001b[39m RandomForest()\n\u001b[1;32m----> 9\u001b[0m forest\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     10\u001b[0m preds \u001b[38;5;241m=\u001b[39m forest\u001b[38;5;241m.\u001b[39mbagging_predict(X_test)\n\u001b[0;32m     11\u001b[0m acc   \u001b[38;5;241m=\u001b[39m forest\u001b[38;5;241m.\u001b[39mget_accuracy(y_test, preds)\n",
      "Cell \u001b[1;32mIn[7], line 25\u001b[0m, in \u001b[0;36mRandomForest.fit\u001b[1;34m(self, X, y, T, max_depth)\u001b[0m\n\u001b[0;32m     23\u001b[0m X_subsample, y_subsample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_subsample(X, y)\n\u001b[0;32m     24\u001b[0m tree \u001b[38;5;241m=\u001b[39m GiniDecisionTreeClassifier(max_depth)\n\u001b[1;32m---> 25\u001b[0m tree\u001b[38;5;241m.\u001b[39mfit(X_subsample, y_subsample)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforest\u001b[38;5;241m.\u001b[39mappend(tree)\n",
      "Cell \u001b[1;32mIn[13], line 97\u001b[0m, in \u001b[0;36mGiniDecisionTreeClassifier.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y):\n\u001b[0;32m     94\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;124;03m    building the tree\u001b[39;00m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[1;32m---> 97\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_root(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit_node(X, y))\n",
      "Cell \u001b[1;32mIn[13], line 109\u001b[0m, in \u001b[0;36mGiniDecisionTreeClassifier.split_node\u001b[1;34m(self, X, y, node_level)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    107\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m leaf(y[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m--> 109\u001b[0m split_feature, split_value, gini  \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_best_split(X, y)\n\u001b[0;32m    111\u001b[0m \u001b[38;5;66;03m# stop condition #2\u001b[39;00m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m gini \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0.0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_depth \u001b[38;5;241m<\u001b[39m node_level :\n",
      "Cell \u001b[1;32mIn[13], line 58\u001b[0m, in \u001b[0;36mGiniDecisionTreeClassifier.get_best_split\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     55\u001b[0m best_split_value        \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     56\u001b[0m best_gini               \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 58\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures_to_check(num_features\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m     59\u001b[0m     values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(X[:, feature])\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m va \u001b[38;5;129;01min\u001b[39;00m values:\n\u001b[0;32m     61\u001b[0m \n\u001b[0;32m     62\u001b[0m         \u001b[38;5;66;03m# split data for specific value and feature:\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[13], line 42\u001b[0m, in \u001b[0;36mGiniDecisionTreeClassifier.features_to_check\u001b[1;34m(self, num_features)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;124;03mInstead of checking all the possible features, we check only some of them that we choose randomly,\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;124;03mit's acceptableto choose the square root of the number of features.\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_features \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m---> 42\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of features must be positive.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     44\u001b[0m num_features_to_check \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(math\u001b[38;5;241m.\u001b[39msqrt(num_features))\n\u001b[0;32m     45\u001b[0m idxs                  \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, num_features, size\u001b[38;5;241m=\u001b[39mnum_features_to_check)\n",
      "\u001b[1;31mValueError\u001b[0m: Number of features must be positive."
     ]
    }
   ],
   "source": [
    "# Data:\n",
    "breast_cancer_data = pd.read_csv('wdbc.data', header=None)\n",
    "X = np.asarray(breast_cancer_data.iloc[:, 2:1])\n",
    "y = np.asarray(breast_cancer_data.iloc[:, 1].astype('str'))\n",
    "\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "forest = RandomForest()\n",
    "forest.fit(X_train, y_train)\n",
    "preds = forest.bagging_predict(X_test)\n",
    "acc   = forest.get_accuracy(y_test, preds)\n",
    "print(\"accuracy is :\", round(acc, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0a164b11-eb23-4c42-8ae4-9171986a193a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0  1      2      3       4       5        6        7       8   \\\n",
       "0    842302  M  17.99  10.38  122.80  1001.0  0.11840  0.27760  0.3001   \n",
       "1    842517  M  20.57  17.77  132.90  1326.0  0.08474  0.07864  0.0869   \n",
       "2  84300903  M  19.69  21.25  130.00  1203.0  0.10960  0.15990  0.1974   \n",
       "3  84348301  M  11.42  20.38   77.58   386.1  0.14250  0.28390  0.2414   \n",
       "4  84358402  M  20.29  14.34  135.10  1297.0  0.10030  0.13280  0.1980   \n",
       "\n",
       "        9   ...     22     23      24      25      26      27      28      29  \\\n",
       "0  0.14710  ...  25.38  17.33  184.60  2019.0  0.1622  0.6656  0.7119  0.2654   \n",
       "1  0.07017  ...  24.99  23.41  158.80  1956.0  0.1238  0.1866  0.2416  0.1860   \n",
       "2  0.12790  ...  23.57  25.53  152.50  1709.0  0.1444  0.4245  0.4504  0.2430   \n",
       "3  0.10520  ...  14.91  26.50   98.87   567.7  0.2098  0.8663  0.6869  0.2575   \n",
       "4  0.10430  ...  22.54  16.67  152.20  1575.0  0.1374  0.2050  0.4000  0.1625   \n",
       "\n",
       "       30       31  \n",
       "0  0.4601  0.11890  \n",
       "1  0.2750  0.08902  \n",
       "2  0.3613  0.08758  \n",
       "3  0.6638  0.17300  \n",
       "4  0.2364  0.07678  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breast_cancer_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbf7441-b5bd-40f8-8bb0-c1d7da00e317",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bdd246b-2ee9-420c-8a6d-46387dff9245",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
